{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost_params_turning.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cv",
      "language": "python",
      "name": "cv"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "23EiQjgIdK1O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. 载入数据"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T00:54:32.699390Z",
          "start_time": "2018-12-27T00:54:31.707045Z"
        },
        "id": "kONCtch3dK1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from  sklearn.datasets  import  make_hastie_10_2\n",
        "from  sklearn.ensemble  import  GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "##载入示例数据 10维度\n",
        "\n",
        "X, y = make_hastie_10_2(random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)##test_size测试集合所占比例"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KuJ3qcabdK1V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 默认GBDT参数"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T00:54:33.423454Z",
          "start_time": "2018-12-27T00:54:32.741278Z"
        },
        "id": "mq6-yOfIdK1W",
        "colab_type": "code",
        "outputId": "87459a67-e20f-4f30-aee4-70aafa4c4cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "clf = GradientBoostingClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pre= clf.predict(X_test)\n",
        "y_pro= clf.predict_proba(X_test)[:,1] \n",
        "print (\"AUC Score : %f\" % metrics.roc_auc_score(y_test, y_pro))\n",
        "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, y_pre)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC Score : 0.974248\n",
            "Accuracy : 0.8995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jjLGYrR2dK1c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 默认XGBoost参数"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T00:54:33.971008Z",
          "start_time": "2018-12-27T00:54:33.459361Z"
        },
        "id": "W-sQ-DxddK1d",
        "colab_type": "code",
        "outputId": "66c75957-8276-4d9f-d15f-371e5805ce70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "auc_Score=[]\n",
        "accuracy=[]\n",
        "clf = XGBClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pre= clf.predict(X_test)\n",
        "y_pro= clf.predict_proba(X_test)[:,1] \n",
        "print (\"AUC Score : %f\" % metrics.roc_auc_score(y_test, y_pro))\n",
        "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, y_pre))\n",
        "auc_Score.append(metrics.roc_auc_score(y_test, y_pro))\n",
        "accuracy.append(metrics.accuracy_score(y_test, y_pre))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC Score : 0.972424\n",
            "Accuracy : 0.8993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P-vKlTWDdK1i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 分步调整XGBoost参数"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T00:54:34.604297Z",
          "start_time": "2018-12-27T00:54:34.011882Z"
        },
        "id": "m2MWlvNadK1k",
        "colab_type": "code",
        "outputId": "ec9c4dd6-5848-49b5-ef64-2e3a32f3dff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "clf = XGBClassifier(\n",
        " learning_rate =0.1, #默认0.3\n",
        " n_estimators=100, #树的个数\n",
        " max_depth=5,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic', #逻辑回归损失函数\n",
        " nthread=4,  #cpu线程数\n",
        " scale_pos_weight=1,\n",
        " seed=27)  #随机种子\n",
        "clf.fit(X_train, y_train)\n",
        "y_pre= clf.predict(X_test)\n",
        "y_pro= clf.predict_proba(X_test)[:,1] \n",
        "print (\"AUC Score : %f\" % metrics.roc_auc_score(y_test, y_pro))\n",
        "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, y_pre)) \n",
        "auc_Score.append(metrics.roc_auc_score(y_test, y_pro))\n",
        "accuracy.append(metrics.accuracy_score(y_test, y_pre))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC Score : 0.979435\n",
            "Accuracy : 0.9177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wqltr35udK1o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 第一步\n",
        "\n",
        "第一步：初始学习速率0.1和tree_based参数调优的估计器数目100 给其他参数一个初始值。\n",
        "\n",
        "1. max_depth = 5 :默认6树的最大深度，这个参数的取值最好在3-10之间。\n",
        "2. min_child_weight = 1:默认是1决定最小叶子节点样本权重和。如果是一个极不平衡的分类问题，某些叶子节点下的值会比较小，这个值取小点。\n",
        "3. gamma = 0: 默认0，在0.1到0.2之间就可以。树的叶子节点上作进一步分裂所需的最小损失减少。这个参数后继也是要调整的。\n",
        "4. subsample, colsample_bytree = 0.8: 样本采样、列采样。典型值的范围在0.5-0.9之间。\n",
        "5. scale_pos_weight = 1:默认1,如果类别十分不平衡取较大正值。"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T01:39:22.124275Z",
          "start_time": "2018-12-27T01:38:52.782708Z"
        },
        "id": "CAWwvGHrdK1p",
        "colab_type": "code",
        "outputId": "d1efcb28-3a5c-4e7e-d68e-5232ba33214f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "tuned_parameters= [{'n_estimators':[100,200,500,1000]\n",
        "                  }]\n",
        "clf = GridSearchCV(XGBClassifier(\n",
        " learning_rate =0.1, #默认0.3\n",
        " max_depth=5,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic', #逻辑回归损失函数\n",
        " nthread=-1,  #cpu线程数,-1表示使用所有线程\n",
        " scale_pos_weight=1,\n",
        " seed=27),  #随机种子 \n",
        " param_grid=tuned_parameters,scoring='roc_auc',n_jobs=-1,iid=False,cv=5) \n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#clf.cv_results_, clf.best_params_, clf.best_score_\n",
        "\n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred))\n",
        "y_proba=clf.predict_proba(X_test)[:,1]\n",
        "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_true, y_proba))\n",
        "\n",
        "clf.cv_results_, clf.best_params_, clf.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9418\n",
            "AUC Score (Train): 0.989438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'mean_fit_time': array([0.66427655, 1.32495356, 3.27263536, 6.16040602]),\n",
              "  'mean_score_time': array([0.01157823, 0.01986165, 0.04536343, 0.0873847 ]),\n",
              "  'mean_test_score': array([0.97632507, 0.98298858, 0.98678414, 0.98780433]),\n",
              "  'mean_train_score': array([0.99961959, 0.99999927, 1.        , 1.        ]),\n",
              "  'param_n_estimators': masked_array(data=[100, 200, 500, 1000],\n",
              "               mask=[False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'params': [{'n_estimators': 100},\n",
              "   {'n_estimators': 200},\n",
              "   {'n_estimators': 500},\n",
              "   {'n_estimators': 1000}],\n",
              "  'rank_test_score': array([4, 3, 2, 1], dtype=int32),\n",
              "  'split0_test_score': array([0.97672398, 0.9852551 , 0.9880359 , 0.98898781]),\n",
              "  'split0_train_score': array([0.99961777, 0.99999791, 1.        , 1.        ]),\n",
              "  'split1_test_score': array([0.97553036, 0.98398993, 0.98780132, 0.98902452]),\n",
              "  'split1_train_score': array([0.99957971, 0.99999896, 1.        , 1.        ]),\n",
              "  'split2_test_score': array([0.97800178, 0.98263884, 0.98601099, 0.98623339]),\n",
              "  'split2_train_score': array([0.99957119, 0.99999948, 1.        , 1.        ]),\n",
              "  'split3_test_score': array([0.97199974, 0.97861895, 0.98379532, 0.98571909]),\n",
              "  'split3_train_score': array([0.9996572, 1.       , 1.       , 1.       ]),\n",
              "  'split4_test_score': array([0.97936947, 0.98444009, 0.98827716, 0.98905683]),\n",
              "  'split4_train_score': array([0.9996721, 1.       , 1.       , 1.       ]),\n",
              "  'std_fit_time': array([0.00671019, 0.00677931, 0.01163194, 0.61743938]),\n",
              "  'std_score_time': array([0.00057199, 0.00014971, 0.00039251, 0.00617809]),\n",
              "  'std_test_score': array([0.00251312, 0.00234362, 0.00169478, 0.00150162]),\n",
              "  'std_train_score': array([4.02685744e-05, 7.80430588e-07, 0.00000000e+00, 0.00000000e+00])},\n",
              " {'n_estimators': 1000},\n",
              " 0.9878043288364371)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "hH9f4g9HdK1u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "得到结论：\n",
        "\n",
        "'n_estimators':[100,200,500,1000,1500]\n",
        "\n",
        "取1000最好"
      ]
    },
    {
      "metadata": {
        "id": "LLJDPbGPdK1x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 第二步\n",
        "\n",
        "第二步： max_depth 和 min_child_weight 它们对最终结果有很大的影响\n",
        "\n",
        "max_depth range(3,10,2)=[3, 5, 7, 9]\n",
        "\n",
        "min_child_weight range(1,6,2)=[1, 3, 5]\n",
        "\n",
        "max_depth=3 min_weight=1 最好\n",
        "\n",
        "\n",
        "**参数注释：**\n",
        "> min_child_weight [default=1]\n",
        ">\n",
        "> Defines the minimum sum of weights of all observations required in a child.\n",
        "This is similar to min_child_leaf in GBM but not exactly. This refers to min “sum of weights” of observations while GBM has min “number of observations”.\n",
        "Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
        "Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
        "\n",
        "> max_depth [default=6]\n",
        ">\n",
        "> The maximum depth of a tree, same as GBM.\n",
        "Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
        "Should be tuned using CV.\n",
        "Typical values: 3-10\n",
        "\n",
        "**关于max_depth**\n",
        "\n",
        "XGBoost 的split方式确定要分割到指定max_depth层，而GBDT则是采用一种贪婪策略，但分割增益小于0即停止。\n",
        "\n",
        "Tree Pruning:\n",
        "- A GBM would stop splitting a node when it encounters a negative loss in the split. Thus it is more of a greedy algorithm.\n",
        "- **XGBoost on the other hand make splits upto the 'max_depth' specified and then start pruning the tree backwards and remove splits beyond which there is no positive gain.**\n",
        "- Another advantage is that sometimes a split of negative loss say -2 may be followed by a split of positive loss +10. GBM would stop as it encounters -2. But XGBoost will go deeper and it will see a combined effect of +8 of the split and keep both."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T01:46:50.464687Z",
          "start_time": "2018-12-27T01:43:58.229074Z"
        },
        "scrolled": true,
        "id": "KJu29p2CdK1x",
        "colab_type": "code",
        "outputId": "3475de46-9c54-4faf-9b16-51c3e8093e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "tuned_parameters= [{'max_depth': range(3,10,2),\n",
        "                    'min_child_weight': range(1,6,2)\n",
        "                  }]\n",
        "clf = GridSearchCV(XGBClassifier(\n",
        " learning_rate =0.1, #默认0.3\n",
        "#  max_depth=5,\n",
        "#  min_child_weight=1,\n",
        " n_estimators = 1000,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic', #逻辑回归损失函数\n",
        " nthread=-1,  #cpu线程数,-1表示使用所有线程\n",
        " scale_pos_weight=1,\n",
        " seed=27),  #随机种子 \n",
        " param_grid=tuned_parameters,scoring='roc_auc',n_jobs=-1,iid=False,cv=5) \n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#clf.cv_results_, clf.best_params_, clf.best_score_\n",
        "\n",
        "print (clf.best_score_)\n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred))\n",
        "y_proba=clf.predict_proba(X_test)[:,1]\n",
        "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_true, y_proba))\n",
        "\n",
        "clf.cv_results_, clf.best_params_, clf.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9902421329970684\n",
            "Accuracy : 0.947\n",
            "AUC Score (Train): 0.991516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'mean_fit_time': array([4.10024233, 4.06720438, 4.04949479, 6.56306758, 6.49959416,\n",
              "         6.23295298, 8.4661417 , 7.95352764, 7.71053686, 9.55492063,\n",
              "         8.61783104, 8.03259201]),\n",
              "  'mean_score_time': array([0.05688643, 0.05727029, 0.05646458, 0.09328356, 0.08852201,\n",
              "         0.08528223, 0.12413554, 0.11121621, 0.10461249, 0.14139628,\n",
              "         0.11906195, 0.1062572 ]),\n",
              "  'mean_test_score': array([0.99024213, 0.98919559, 0.98771132, 0.98780433, 0.98647996,\n",
              "         0.98359491, 0.98496889, 0.98328829, 0.98064576, 0.98405483,\n",
              "         0.98209103, 0.98019748]),\n",
              "  'mean_train_score': array([1.        , 0.99999496, 0.99993488, 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        ]),\n",
              "  'param_max_depth': masked_array(data=[3, 3, 3, 5, 5, 5, 7, 7, 7, 9, 9, 9],\n",
              "               mask=[False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
              "               mask=[False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'params': [{'max_depth': 3, 'min_child_weight': 1},\n",
              "   {'max_depth': 3, 'min_child_weight': 3},\n",
              "   {'max_depth': 3, 'min_child_weight': 5},\n",
              "   {'max_depth': 5, 'min_child_weight': 1},\n",
              "   {'max_depth': 5, 'min_child_weight': 3},\n",
              "   {'max_depth': 5, 'min_child_weight': 5},\n",
              "   {'max_depth': 7, 'min_child_weight': 1},\n",
              "   {'max_depth': 7, 'min_child_weight': 3},\n",
              "   {'max_depth': 7, 'min_child_weight': 5},\n",
              "   {'max_depth': 9, 'min_child_weight': 1},\n",
              "   {'max_depth': 9, 'min_child_weight': 3},\n",
              "   {'max_depth': 9, 'min_child_weight': 5}],\n",
              "  'rank_test_score': array([ 1,  2,  4,  3,  5,  8,  6,  9, 11,  7, 10, 12], dtype=int32),\n",
              "  'split0_test_score': array([0.99074454, 0.98885182, 0.98746697, 0.98898781, 0.98708399,\n",
              "         0.98411447, 0.98669823, 0.98532171, 0.98176106, 0.9858268 ,\n",
              "         0.98367598, 0.98142248]),\n",
              "  'split0_train_score': array([1.        , 0.99999444, 0.99994994, 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        ]),\n",
              "  'split1_test_score': array([0.99130135, 0.99077871, 0.98932754, 0.98902452, 0.98822944,\n",
              "         0.98553561, 0.98566905, 0.98522147, 0.9816992 , 0.98577191,\n",
              "         0.98380088, 0.98100142]),\n",
              "  'split1_train_score': array([1.        , 0.99999548, 0.99993224, 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        ]),\n",
              "  'split2_test_score': array([0.98984741, 0.98898838, 0.98705906, 0.98623339, 0.98556619,\n",
              "         0.9820745 , 0.98445419, 0.98278062, 0.97925835, 0.9838815 ,\n",
              "         0.98177704, 0.97901927]),\n",
              "  'split2_train_score': array([1.        , 0.99999218, 0.99992616, 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        ]),\n",
              "  'split3_test_score': array([0.98750108, 0.98627231, 0.98603323, 0.98571909, 0.98437913,\n",
              "         0.9821162 , 0.98257212, 0.98025081, 0.97922777, 0.98195496,\n",
              "         0.97892753, 0.97906097]),\n",
              "  'split3_train_score': array([1.        , 1.        , 0.99998245, 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        ]),\n",
              "  'split4_test_score': array([0.99181629, 0.99108674, 0.98866978, 0.98905683, 0.98714108,\n",
              "         0.98413379, 0.98545087, 0.98286683, 0.98128244, 0.98283899,\n",
              "         0.98227373, 0.98048328]),\n",
              "  'split4_train_score': array([1.        , 0.99999271, 0.99988364, 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        ]),\n",
              "  'std_fit_time': array([0.01405666, 0.01141309, 0.01793645, 0.11919028, 0.15385108,\n",
              "         0.017553  , 0.00900605, 0.01608282, 0.05402459, 0.05556089,\n",
              "         0.04126622, 0.42052395]),\n",
              "  'std_score_time': array([0.00072866, 0.00059386, 0.00050668, 0.00325519, 0.00256326,\n",
              "         0.00031589, 0.00093075, 0.00050676, 0.00083621, 0.00106848,\n",
              "         0.00128343, 0.00827042]),\n",
              "  'std_test_score': array([0.00151799, 0.00171985, 0.00116893, 0.00150162, 0.00134989,\n",
              "         0.00132853, 0.00139446, 0.00187262, 0.00115712, 0.00154958,\n",
              "         0.00176496, 0.0009908 ]),\n",
              "  'std_train_score': array([0.00000000e+00, 2.78389460e-06, 3.22451414e-05, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])},\n",
              " {'max_depth': 3, 'min_child_weight': 1},\n",
              " 0.9902421329970684)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "THq0PyaqdK13",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "结果表明：\n",
        "\n",
        "max_depth=3 min_child_weight=1 最好"
      ]
    },
    {
      "metadata": {
        "id": "XMvyOgHidK13",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 第三步\n",
        "\n",
        "第三步：gamma参数调优\n",
        "\n",
        "'gamma':[i/10.0 for i in range(0,7)]=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "\n",
        "\n",
        "> gamma [default=0, alias: min_split_loss]\n",
        "\n",
        "> Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.\n",
        "\n",
        "> range: [0,∞]"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T01:56:32.816797Z",
          "start_time": "2018-12-27T01:55:35.520952Z"
        },
        "id": "6VfI901CdK15",
        "colab_type": "code",
        "outputId": "76dda289-f921-4815-9b39-e8e518829b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "tuned_parameters= [{'gamma':[i/10.0 for i in range(0,7)]\n",
        "                  }]\n",
        "clf = GridSearchCV(XGBClassifier(\n",
        " learning_rate =0.1, #默认0.3\n",
        " n_estimators=1000, #树的个数\n",
        " max_depth=3,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic', #逻辑回归损失函数\n",
        " nthread=-1,  #cpu线程数,-1表示使用所有线程\n",
        " scale_pos_weight=1,\n",
        " seed=27),  #随机种子 \n",
        " param_grid=tuned_parameters,scoring='roc_auc',n_jobs=-1,iid=False,cv=5) \n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred))\n",
        "y_proba=clf.predict_proba(X_test)[:,1]\n",
        "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_true, y_proba))\n",
        "clf.cv_results_, clf.best_params_, clf.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9523\n",
            "AUC Score (Train): 0.992072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'mean_fit_time': array([4.08784242, 4.13580532, 4.15678062, 4.104004  , 4.10653367,\n",
              "         4.11219459, 3.84211726]),\n",
              "  'mean_score_time': array([0.05971794, 0.05829625, 0.05696807, 0.05853791, 0.05707612,\n",
              "         0.05631042, 0.05412021]),\n",
              "  'mean_test_score': array([0.99024213, 0.99031935, 0.99040982, 0.99055717, 0.99063991,\n",
              "         0.9907346 , 0.99117328]),\n",
              "  'mean_train_score': array([1.        , 0.99999997, 1.        , 1.        , 0.99999986,\n",
              "         0.99999983, 0.99999986]),\n",
              "  'param_gamma': masked_array(data=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
              "               mask=[False, False, False, False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'params': [{'gamma': 0.0},\n",
              "   {'gamma': 0.1},\n",
              "   {'gamma': 0.2},\n",
              "   {'gamma': 0.3},\n",
              "   {'gamma': 0.4},\n",
              "   {'gamma': 0.5},\n",
              "   {'gamma': 0.6}],\n",
              "  'rank_test_score': array([7, 6, 5, 4, 3, 2, 1], dtype=int32),\n",
              "  'split0_test_score': array([0.99074454, 0.99088053, 0.99110255, 0.99115806, 0.99075564,\n",
              "         0.99153827, 0.99167425]),\n",
              "  'split0_train_score': array([1.        , 1.        , 1.        , 1.        , 0.99999965,\n",
              "         0.99999965, 0.99999983]),\n",
              "  'split1_test_score': array([0.99130135, 0.99144591, 0.99225489, 0.99169611, 0.99125965,\n",
              "         0.99162661, 0.99260795]),\n",
              "  'split1_train_score': array([1., 1., 1., 1., 1., 1., 1.]),\n",
              "  'split2_test_score': array([0.98984741, 0.99023383, 0.98963056, 0.99024773, 0.99030889,\n",
              "         0.99002255, 0.99027553]),\n",
              "  'split2_train_score': array([1.        , 0.99999983, 1.        , 1.        , 0.99999965,\n",
              "         0.99999948, 0.99999948]),\n",
              "  'split3_test_score': array([0.98750108, 0.98727034, 0.98756502, 0.98808488, 0.98832118,\n",
              "         0.98830728, 0.98900506]),\n",
              "  'split3_train_score': array([1., 1., 1., 1., 1., 1., 1.]),\n",
              "  'split4_test_score': array([0.99181629, 0.99176617, 0.99149607, 0.9915991 , 0.99255419,\n",
              "         0.99217828, 0.99230358]),\n",
              "  'split4_train_score': array([1., 1., 1., 1., 1., 1., 1.]),\n",
              "  'std_fit_time': array([0.01378078, 0.04815563, 0.04390025, 0.00805336, 0.01261062,\n",
              "         0.01242839, 0.53625721]),\n",
              "  'std_score_time': array([0.00285409, 0.00224898, 0.00153852, 0.00176098, 0.00165367,\n",
              "         0.0002984 , 0.00455792]),\n",
              "  'std_test_score': array([0.00151799, 0.00161128, 0.00165917, 0.00133805, 0.00138188,\n",
              "         0.00140888, 0.00134863]),\n",
              "  'std_train_score': array([0.00000000e+00, 6.94986075e-08, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.70272633e-07, 2.19797461e-07, 2.02624076e-07])},\n",
              " {'gamma': 0.6},\n",
              " 0.991173275197764)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "ILDOdXFQdK1_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "结果显示：\n",
        "\n",
        "gamma=0.6 最好"
      ]
    },
    {
      "metadata": {
        "id": "abnI6PoNdK2A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 第四步\n",
        "\n",
        "第四步：调整subsample 和 colsample_bytree 参数\n",
        "\n",
        "'subsample':[i/10.0 for i in range(6,10)]=[0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "'colsample_bytree':[i/10.0 for i in range(6,10)]=[0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "'subsample': 0.6, 'colsample_bytree': 0.6 最好"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T01:52:19.996323Z",
          "start_time": "2018-12-27T01:50:08.124055Z"
        },
        "id": "pdufltuwdK2C",
        "colab_type": "code",
        "outputId": "47089bb7-d516-4f64-eb4d-cb731e81bdce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1747
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "tuned_parameters= [{'subsample':[i/10.0 for i in range(6,10)],\n",
        "                    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
        "                   }]\n",
        "clf = GridSearchCV(XGBClassifier(\n",
        " learning_rate =0.1, #默认0.3\n",
        " n_estimators=1000, #树的个数\n",
        " max_depth=3,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic', #逻辑回归损失函数\n",
        " nthread=-1,  #cpu线程数,-1表示使用所有线程\n",
        " scale_pos_weight=1,\n",
        " seed=27),  #随机种子 \n",
        " param_grid=tuned_parameters,scoring='roc_auc',n_jobs=-1,iid=False,cv=5) \n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#clf.cv_results_, clf.best_params_, clf.best_score_\n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred))\n",
        "y_proba=clf.predict_proba(X_test)[:,1]\n",
        "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_true, y_proba))\n",
        "clf.cv_results_, clf.best_params_, clf.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9522\n",
            "AUC Score (Train): 0.992397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'mean_fit_time': array([3.34788318, 3.38439374, 3.43055534, 3.47929316, 3.63930459,\n",
              "         3.88183041, 4.04542418, 3.82146721, 3.95433326, 4.02437754,\n",
              "         4.08732462, 4.19291725, 4.27289486, 4.355165  , 4.43081102,\n",
              "         4.49650884]),\n",
              "  'mean_score_time': array([0.05811257, 0.05756421, 0.05767741, 0.05814404, 0.05732098,\n",
              "         0.06595297, 0.05695639, 0.0562304 , 0.05646   , 0.05626922,\n",
              "         0.05605416, 0.05591116, 0.05628901, 0.05641556, 0.05595517,\n",
              "         0.05382738]),\n",
              "  'mean_test_score': array([0.99136929, 0.99111036, 0.9908039 , 0.98996486, 0.99109902,\n",
              "         0.99112067, 0.99051957, 0.9901156 , 0.99119806, 0.99071939,\n",
              "         0.99024213, 0.98978984, 0.9909985 , 0.99081676, 0.99009991,\n",
              "         0.98948751]),\n",
              "  'mean_train_score': array([0.99999969, 0.99999993, 0.99999997, 1.        , 0.99999927,\n",
              "         0.99999993, 0.99999997, 1.        , 0.9999999 , 0.99999972,\n",
              "         1.        , 1.        , 0.99999976, 0.9999999 , 0.99999997,\n",
              "         1.        ]),\n",
              "  'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8,\n",
              "                     0.8, 0.9, 0.9, 0.9, 0.9],\n",
              "               mask=[False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False, False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'param_subsample': masked_array(data=[0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
              "                     0.9, 0.6, 0.7, 0.8, 0.9],\n",
              "               mask=[False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False, False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'params': [{'colsample_bytree': 0.6, 'subsample': 0.6},\n",
              "   {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
              "   {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
              "   {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
              "   {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
              "   {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
              "   {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
              "   {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
              "   {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
              "   {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
              "   {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
              "   {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
              "   {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
              "   {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
              "   {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
              "   {'colsample_bytree': 0.9, 'subsample': 0.9}],\n",
              "  'rank_test_score': array([ 1,  4,  8, 14,  5,  3, 10, 12,  2,  9, 11, 15,  6,  7, 13, 16],\n",
              "        dtype=int32),\n",
              "  'split0_test_score': array([0.99129959, 0.99074732, 0.99070847, 0.99041151, 0.99070569,\n",
              "         0.99139395, 0.99065019, 0.99108035, 0.99209331, 0.99106925,\n",
              "         0.99074454, 0.99054195, 0.99181857, 0.99077507, 0.99045869,\n",
              "         0.99015897]),\n",
              "  'split0_train_score': array([0.99999965, 0.99999983, 1.        , 1.        , 0.99999791,\n",
              "         0.99999983, 0.99999983, 1.        , 0.99999983, 0.99999965,\n",
              "         1.        , 1.        , 0.99999965, 1.        , 1.        ,\n",
              "         1.        ]),\n",
              "  'split1_test_score': array([0.9934086 , 0.99278866, 0.99211589, 0.99141255, 0.99296936,\n",
              "         0.99212979, 0.99183233, 0.99145703, 0.9932001 , 0.99155433,\n",
              "         0.99130135, 0.99156545, 0.99230493, 0.99214369, 0.99101223,\n",
              "         0.99114289]),\n",
              "  'split1_train_score': array([1.        , 1.        , 1.        , 1.        , 0.99999965,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "         1.        ]),\n",
              "  'split2_test_score': array([0.99075647, 0.99052017, 0.98993359, 0.98851022, 0.99112621,\n",
              "         0.99057021, 0.98995305, 0.98937758, 0.99011151, 0.99037283,\n",
              "         0.98984741, 0.9892775 , 0.99077871, 0.99054519, 0.98934422,\n",
              "         0.98898282]),\n",
              "  'split2_train_score': array([0.99999913, 0.99999983, 0.99999983, 1.        , 0.99999983,\n",
              "         0.99999983, 1.        , 1.        , 0.99999983, 0.99999948,\n",
              "         1.        , 1.        , 0.99999913, 0.99999965, 0.99999983,\n",
              "         1.        ]),\n",
              "  'split3_test_score': array([0.98852968, 0.98872984, 0.9888605 , 0.98749552, 0.98865756,\n",
              "         0.98883548, 0.98847964, 0.98747328, 0.9885547 , 0.98779576,\n",
              "         0.98750108, 0.98678939, 0.98822944, 0.9879153 , 0.98782078,\n",
              "         0.98633903]),\n",
              "  'split3_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
              "  'split4_test_score': array([0.99285213, 0.99276581, 0.99240104, 0.9919945 , 0.99203627,\n",
              "         0.99267392, 0.99168263, 0.99118977, 0.9920307 , 0.99280479,\n",
              "         0.99181629, 0.99077488, 0.99186084, 0.99270455, 0.99186363,\n",
              "         0.99081386]),\n",
              "  'split4_train_score': array([0.99999965, 1.        , 1.        , 1.        , 0.99999896,\n",
              "         1.        , 1.        , 1.        , 0.99999983, 0.99999948,\n",
              "         1.        , 1.        , 1.        , 0.99999983, 1.        ,\n",
              "         1.        ]),\n",
              "  'std_fit_time': array([0.01738095, 0.00967988, 0.0106058 , 0.00466171, 0.00650665,\n",
              "         0.12905311, 0.35069167, 0.00833264, 0.01511322, 0.01169423,\n",
              "         0.01006915, 0.055133  , 0.0247075 , 0.00591088, 0.00529854,\n",
              "         0.05425587]),\n",
              "  'std_score_time': array([0.00089941, 0.00099629, 0.00192596, 0.00216851, 0.00125375,\n",
              "         0.00643969, 0.00091569, 0.00029168, 0.00032408, 0.00030256,\n",
              "         0.00036829, 0.00025315, 0.00021594, 0.00022433, 0.00010953,\n",
              "         0.00453534]),\n",
              "  'std_test_score': array([0.00172055, 0.00152998, 0.00132782, 0.00171046, 0.00144864,\n",
              "         0.00134393, 0.00123088, 0.00151067, 0.00165353, 0.0016635 ,\n",
              "         0.00151799, 0.00167056, 0.00147234, 0.00166244, 0.00140266,\n",
              "         0.00173885]),\n",
              "  'std_train_score': array([3.18482822e-07, 8.51363164e-08, 6.94986075e-08, 0.00000000e+00,\n",
              "         7.64767179e-07, 8.51363164e-08, 6.95284097e-08, 0.00000000e+00,\n",
              "         8.51187459e-08, 2.35646463e-07, 0.00000000e+00, 0.00000000e+00,\n",
              "         3.40481383e-07, 1.38990178e-07, 6.94986075e-08, 0.00000000e+00])},\n",
              " {'colsample_bytree': 0.6, 'subsample': 0.6},\n",
              " 0.9913692942072346)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "TKySZaM9dK2H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 第五步\n",
        "\n",
        "第五步：正则化参数调优\n",
        "\n",
        "'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]=[1e-05, 0.01, 0.1, 1, 100] 默认0 L1正则项参数，参数值越大，模型越不容易过拟合\n",
        "\n",
        "'reg_lambda':[1,5,10,50] 默认1L2正则项参数，参数值越大，模型越不容易过拟合\n",
        "\n",
        "{'reg_alpha': 1e-05, 'reg_lambda': 1} 正则变化不大\n",
        "\n",
        "> lambda [default=1, alias: reg_lambda]\n",
        "\n",
        "> L2 regularization term on weights. Increasing this value will make model more conservative.\n",
        "alpha [default=0, alias: reg_alpha]\n",
        "\n",
        "> L1 regularization term on weights. Increasing this value will make model more conservative."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T02:04:20.878510Z",
          "start_time": "2018-12-27T02:02:22.361310Z"
        },
        "id": "wEjfR4cvdK2I",
        "colab_type": "code",
        "outputId": "e7a2c459-2607-47e5-f0db-c85088f7430b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1915
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "tuned_parameters= [{'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
        "                    'reg_lambda':[1,5,10,50]\n",
        "                   }]\n",
        "clf = GridSearchCV(XGBClassifier(\n",
        " learning_rate =0.1, #默认0.3\n",
        " n_estimators=1000, #树的个数\n",
        " max_depth=3,\n",
        " min_child_weight=1,\n",
        " gamma=0.6,\n",
        " subsample=0.6,\n",
        " colsample_bytree=0.6,\n",
        " objective= 'binary:logistic', #逻辑回归损失函数\n",
        " nthread=-1,  #cpu线程数,-1表示使用所有线程\n",
        " scale_pos_weight=1,\n",
        " seed=27),  #随机种子 \n",
        " param_grid=tuned_parameters,scoring='roc_auc',n_jobs=-1,iid=False,cv=5) \n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#clf.cv_results_, clf.best_params_, clf.best_score_\n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred))\n",
        "y_proba=clf.predict_proba(X_test)[:,1]\n",
        "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_true, y_proba))\n",
        "clf.cv_results_, clf.best_params_, clf.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9555\n",
            "AUC Score (Train): 0.992868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'mean_fit_time': array([3.57523336, 3.59076009, 3.60481343, 3.62930899, 3.58253379,\n",
              "         3.60277076, 3.62260051, 3.64259949, 3.60844054, 3.62169762,\n",
              "         3.63268323, 3.64931197, 3.65102282, 3.65047541, 3.66717477,\n",
              "         3.66272306, 1.77348022, 1.75979638, 1.75771828, 1.75320315]),\n",
              "  'mean_score_time': array([0.05806079, 0.05884867, 0.05991797, 0.05784712, 0.05824041,\n",
              "         0.05812812, 0.05788779, 0.05805917, 0.05803089, 0.05853901,\n",
              "         0.0578908 , 0.05916243, 0.0581624 , 0.06054859, 0.06007977,\n",
              "         0.06048918, 0.00946679, 0.0094245 , 0.00934477, 0.00884004]),\n",
              "  'mean_test_score': array([0.9922044 , 0.9903245 , 0.98835779, 0.97808582, 0.99241992,\n",
              "         0.99042686, 0.98836973, 0.97806353, 0.99218883, 0.99016637,\n",
              "         0.98819365, 0.97793884, 0.9912895 , 0.98909203, 0.98694434,\n",
              "         0.97694493, 0.77610178, 0.77795469, 0.77577765, 0.771155  ]),\n",
              "  'mean_train_score': array([0.9999984 , 0.99984488, 0.99936388, 0.99399755, 0.99999805,\n",
              "         0.99984829, 0.99934877, 0.99398011, 0.9999968 , 0.99981886,\n",
              "         0.99931413, 0.99392284, 0.9999297 , 0.99954614, 0.99884219,\n",
              "         0.99307182, 0.8136743 , 0.81547369, 0.81336072, 0.80796742]),\n",
              "  'param_reg_alpha': masked_array(data=[1e-05, 1e-05, 1e-05, 1e-05, 0.01, 0.01, 0.01, 0.01,\n",
              "                     0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 100, 100, 100, 100],\n",
              "               mask=[False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'param_reg_lambda': masked_array(data=[1, 5, 10, 50, 1, 5, 10, 50, 1, 5, 10, 50, 1, 5, 10, 50,\n",
              "                     1, 5, 10, 50],\n",
              "               mask=[False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'params': [{'reg_alpha': 1e-05, 'reg_lambda': 1},\n",
              "   {'reg_alpha': 1e-05, 'reg_lambda': 5},\n",
              "   {'reg_alpha': 1e-05, 'reg_lambda': 10},\n",
              "   {'reg_alpha': 1e-05, 'reg_lambda': 50},\n",
              "   {'reg_alpha': 0.01, 'reg_lambda': 1},\n",
              "   {'reg_alpha': 0.01, 'reg_lambda': 5},\n",
              "   {'reg_alpha': 0.01, 'reg_lambda': 10},\n",
              "   {'reg_alpha': 0.01, 'reg_lambda': 50},\n",
              "   {'reg_alpha': 0.1, 'reg_lambda': 1},\n",
              "   {'reg_alpha': 0.1, 'reg_lambda': 5},\n",
              "   {'reg_alpha': 0.1, 'reg_lambda': 10},\n",
              "   {'reg_alpha': 0.1, 'reg_lambda': 50},\n",
              "   {'reg_alpha': 1, 'reg_lambda': 1},\n",
              "   {'reg_alpha': 1, 'reg_lambda': 5},\n",
              "   {'reg_alpha': 1, 'reg_lambda': 10},\n",
              "   {'reg_alpha': 1, 'reg_lambda': 50},\n",
              "   {'reg_alpha': 100, 'reg_lambda': 1},\n",
              "   {'reg_alpha': 100, 'reg_lambda': 5},\n",
              "   {'reg_alpha': 100, 'reg_lambda': 10},\n",
              "   {'reg_alpha': 100, 'reg_lambda': 50}],\n",
              "  'rank_test_score': array([ 2,  6, 10, 13,  1,  5,  9, 14,  3,  7, 11, 15,  4,  8, 12, 16, 18,\n",
              "         17, 19, 20], dtype=int32),\n",
              "  'split0_test_score': array([0.99215715, 0.98956784, 0.98751693, 0.9765991 , 0.9927122 ,\n",
              "         0.98962889, 0.98758354, 0.97685442, 0.99207111, 0.98978708,\n",
              "         0.98710897, 0.97685442, 0.9910526 , 0.9880248 , 0.98550487,\n",
              "         0.97539464, 0.77952865, 0.77970072, 0.77240181, 0.77170384]),\n",
              "  'split0_train_score': array([0.9999993 , 0.99983748, 0.99931393, 0.99406453, 0.99999652,\n",
              "         0.99982044, 0.99930367, 0.99414953, 0.99999774, 0.99982183,\n",
              "         0.9992743 , 0.99398405, 0.99991848, 0.99953381, 0.99881385,\n",
              "         0.99310522, 0.80560326, 0.80571511, 0.8003616 , 0.80160216]),\n",
              "  'split1_test_score': array([0.9937144 , 0.99240223, 0.99045067, 0.97955303, 0.99358096,\n",
              "         0.99241335, 0.98976957, 0.97915271, 0.99382004, 0.99209921,\n",
              "         0.99020881, 0.97911657, 0.99311948, 0.99100945, 0.98882992,\n",
              "         0.97847717, 0.7595959 , 0.75975436, 0.75550789, 0.75297948]),\n",
              "  'split1_train_score': array([0.99999913, 0.99984398, 0.99925324, 0.99367511, 0.99999826,\n",
              "         0.99985127, 0.99930571, 0.993607  , 0.99999792, 0.9998332 ,\n",
              "         0.99927652, 0.99360005, 0.9999477 , 0.99955417, 0.9986896 ,\n",
              "         0.9927327 , 0.80173568, 0.80186468, 0.79715016, 0.79497146]),\n",
              "  'split2_test_score': array([0.99179063, 0.9891246 , 0.98675325, 0.97687866, 0.99204917,\n",
              "         0.98942762, 0.98674491, 0.97722616, 0.99178229, 0.98881602,\n",
              "         0.98702848, 0.97757922, 0.99019769, 0.9876651 , 0.98522703,\n",
              "         0.97614752, 0.79911373, 0.79913597, 0.79869534, 0.79015376]),\n",
              "  'split2_train_score': array([0.99999809, 0.99979724, 0.99940683, 0.99422901, 0.99999844,\n",
              "         0.99982556, 0.99935679, 0.99423266, 0.99999583, 0.99978108,\n",
              "         0.99931457, 0.99425994, 0.9998961 , 0.99944088, 0.99893563,\n",
              "         0.99339207, 0.82645989, 0.82642097, 0.82371174, 0.81447825]),\n",
              "  'split3_test_score': array([0.98964168, 0.98971118, 0.98882158, 0.98019243, 0.99006703,\n",
              "         0.98960832, 0.98863532, 0.97977543, 0.98964446, 0.98978903,\n",
              "         0.98834064, 0.97928337, 0.99037561, 0.9890134 , 0.98762896,\n",
              "         0.97871625, 0.79577494, 0.7958361 , 0.79782659, 0.79339247]),\n",
              "  'split3_train_score': array([1.        , 0.99994457, 0.99959222, 0.99433847, 1.        ,\n",
              "         0.99994979, 0.99958353, 0.99424882, 1.        , 0.99990461,\n",
              "         0.99956233, 0.99419235, 0.99997203, 0.99970255, 0.99910329,\n",
              "         0.9933495 , 0.83876636, 0.83876314, 0.84353457, 0.83296383]),\n",
              "  'split4_test_score': array([0.99371812, 0.99081664, 0.98824653, 0.9772059 , 0.99369027,\n",
              "         0.99105611, 0.9891153 , 0.97730893, 0.99362623, 0.99034049,\n",
              "         0.98828134, 0.97686062, 0.99170212, 0.98974739, 0.98753091,\n",
              "         0.97598906, 0.74649568, 0.75534628, 0.75445663, 0.74754544]),\n",
              "  'split4_train_score': array([0.99999548, 0.99980114, 0.99925319, 0.99368062, 0.99999705,\n",
              "         0.99979437, 0.99919414, 0.99366256, 0.99999253, 0.99975355,\n",
              "         0.99914291, 0.9935778 , 0.9999142 , 0.99949929, 0.9986686 ,\n",
              "         0.99277959, 0.79580629, 0.80460455, 0.80204552, 0.7958214 ]),\n",
              "  'std_fit_time': array([0.01191243, 0.01325173, 0.00659292, 0.00438262, 0.01042653,\n",
              "         0.01166532, 0.02686689, 0.0092751 , 0.00576707, 0.00575164,\n",
              "         0.00630358, 0.00739558, 0.00739137, 0.00888037, 0.01325656,\n",
              "         0.01174046, 0.01253897, 0.01083901, 0.01408579, 0.03089126]),\n",
              "  'std_score_time': array([0.00063335, 0.00045964, 0.00207908, 0.00077044, 0.00090627,\n",
              "         0.00138421, 0.00118615, 0.000901  , 0.00116144, 0.00164232,\n",
              "         0.00092595, 0.000837  , 0.00206178, 0.00349466, 0.0042768 ,\n",
              "         0.00541115, 0.00036815, 0.0002026 , 0.00013465, 0.00142456]),\n",
              "  'std_test_score': array([0.00150415, 0.00117878, 0.00125612, 0.00148542, 0.00132067,\n",
              "         0.00115303, 0.00108112, 0.00117042, 0.00150863, 0.00108406,\n",
              "         0.00115103, 0.0010642 , 0.00105853, 0.00120725, 0.00137036,\n",
              "         0.00137392, 0.0203828 , 0.0179657 , 0.01943307, 0.01867362]),\n",
              "  'std_train_score': array([1.58181542e-06, 5.32495526e-05, 1.27256443e-04, 2.75209409e-04,\n",
              "         1.21093013e-06, 5.38709812e-05, 1.28820776e-04, 2.84513597e-04,\n",
              "         2.51096229e-06, 5.14985044e-05, 1.37056730e-04, 2.87492944e-04,\n",
              "         2.68726271e-05, 8.71239048e-05, 1.61942019e-04, 2.76110081e-04,\n",
              "         1.62482048e-02, 1.45658140e-02, 1.77617460e-02, 1.43118733e-02])},\n",
              " {'reg_alpha': 0.01, 'reg_lambda': 1},\n",
              " 0.9924199248863191)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "GhLbyRyZdK2P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 第六步\n",
        "\n",
        "第6步：进一步 降低学习速率 增加更多的树\n",
        "\n",
        "'learning_rate':[0.01,0.1,0.3]\n",
        "\n",
        "'learning_rate': 0.1 不变\n",
        "\n",
        "'n_estimators':[1000,1200,1500,2000,2500]\n",
        "\n",
        "'n_estimators': 1500 较好"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-12-27T02:09:32.205243Z",
          "start_time": "2018-12-27T02:06:53.084576Z"
        },
        "id": "NuEwDJuvdK2Q",
        "colab_type": "code",
        "outputId": "9fa01141-fe0c-4fbb-eda1-d6ffbb2570e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1495
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "tuned_parameters= [{'learning_rate':[0.01,0.1,0.3],\n",
        "                    'n_estimators':[1000,1200,1500,2000,2500]\n",
        "                   }]\n",
        "clf = GridSearchCV(XGBClassifier(\n",
        " learning_rate =0.1, #默认0.3\n",
        " n_estimators=1000, #树的个数\n",
        " max_depth=3,\n",
        " min_child_weight=1,\n",
        " gamma=0.6,\n",
        " subsample=0.6,\n",
        " colsample_bytree=0.6,\n",
        " objective= 'binary:logistic', #逻辑回归损失函数\n",
        " nthread=-1,  #cpu线程数,-1表示使用所有线程\n",
        " scale_pos_weight=1,\n",
        " reg_alpha = 1e-05,\n",
        " reg_lambda = 1,\n",
        " seed=27),  #随机种子 \n",
        " param_grid=tuned_parameters,scoring='roc_auc',n_jobs=-1,iid=False,cv=5) \n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#clf.cv_results_, clf.best_params_, clf.best_score_\n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred))\n",
        "y_proba=clf.predict_proba(X_test)[:,1]\n",
        "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_true, y_proba))\n",
        "clf.cv_results_, clf.best_params_, clf.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9538\n",
            "AUC Score (Train): 0.993026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'mean_fit_time': array([3.57008743, 4.77174163, 5.36605616, 7.1552011 , 8.94790907,\n",
              "         3.59686456, 4.31058722, 5.36648741, 7.13045301, 8.86648717,\n",
              "         3.56040711, 4.24546318, 5.31230602, 7.04101019, 8.50523062]),\n",
              "  'mean_score_time': array([0.05733538, 0.07500162, 0.08352704, 0.11490374, 0.15462112,\n",
              "         0.05688457, 0.0685442 , 0.08289218, 0.10480108, 0.12060022,\n",
              "         0.04361629, 0.04652081, 0.0500608 , 0.05485482, 0.056601  ]),\n",
              "  'mean_test_score': array([0.97739301, 0.98025168, 0.98320005, 0.98611754, 0.987942  ,\n",
              "         0.9922044 , 0.9925075 , 0.99244789, 0.99224707, 0.99213971,\n",
              "         0.99118297, 0.99093487, 0.99091936, 0.99061469, 0.99058739]),\n",
              "  'mean_train_score': array([0.99421428, 0.99584249, 0.99740946, 0.99872319, 0.9993335 ,\n",
              "         0.9999984 , 0.99999948, 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              "  'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                     0.3, 0.3, 0.3, 0.3, 0.3],\n",
              "               mask=[False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'param_n_estimators': masked_array(data=[1000, 1200, 1500, 2000, 2500, 1000, 1200, 1500, 2000,\n",
              "                     2500, 1000, 1200, 1500, 2000, 2500],\n",
              "               mask=[False, False, False, False, False, False, False, False,\n",
              "                     False, False, False, False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'params': [{'learning_rate': 0.01, 'n_estimators': 1000},\n",
              "   {'learning_rate': 0.01, 'n_estimators': 1200},\n",
              "   {'learning_rate': 0.01, 'n_estimators': 1500},\n",
              "   {'learning_rate': 0.01, 'n_estimators': 2000},\n",
              "   {'learning_rate': 0.01, 'n_estimators': 2500},\n",
              "   {'learning_rate': 0.1, 'n_estimators': 1000},\n",
              "   {'learning_rate': 0.1, 'n_estimators': 1200},\n",
              "   {'learning_rate': 0.1, 'n_estimators': 1500},\n",
              "   {'learning_rate': 0.1, 'n_estimators': 2000},\n",
              "   {'learning_rate': 0.1, 'n_estimators': 2500},\n",
              "   {'learning_rate': 0.3, 'n_estimators': 1000},\n",
              "   {'learning_rate': 0.3, 'n_estimators': 1200},\n",
              "   {'learning_rate': 0.3, 'n_estimators': 1500},\n",
              "   {'learning_rate': 0.3, 'n_estimators': 2000},\n",
              "   {'learning_rate': 0.3, 'n_estimators': 2500}],\n",
              "  'rank_test_score': array([15, 14, 13, 12, 11,  4,  1,  2,  3,  5,  6,  7,  8,  9, 10],\n",
              "        dtype=int32),\n",
              "  'split0_test_score': array([0.9771264 , 0.97916065, 0.98176661, 0.9849415 , 0.98700351,\n",
              "         0.99215715, 0.99230146, 0.99243745, 0.99235141, 0.99238194,\n",
              "         0.99104705, 0.99111643, 0.99103039, 0.99066684, 0.99062521]),\n",
              "  'split0_train_score': array([0.99420811, 0.99570905, 0.99736487, 0.99865723, 0.9993254 ,\n",
              "         0.9999993 , 0.99999965, 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              "  'split1_test_score': array([0.97502161, 0.97882745, 0.98241088, 0.98607771, 0.98859084,\n",
              "         0.9937144 , 0.9939229 , 0.993909  , 0.99381726, 0.99369772,\n",
              "         0.99299994, 0.99264409, 0.99277754, 0.99248285, 0.99235219]),\n",
              "  'split1_train_score': array([0.99364731, 0.99556529, 0.99717784, 0.9986585 , 0.99931266,\n",
              "         0.99999913, 0.99999948, 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              "  'split2_test_score': array([0.98010069, 0.9825749 , 0.98531321, 0.9875539 , 0.98890498,\n",
              "         0.99179063, 0.99205195, 0.99213257, 0.99159325, 0.99136807,\n",
              "         0.9897501 , 0.98914406, 0.98908012, 0.98874096, 0.98881324]),\n",
              "  'split2_train_score': array([0.99436401, 0.99585667, 0.99737764, 0.9987485 , 0.99934324,\n",
              "         0.99999809, 0.99999965, 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              "  'split3_test_score': array([0.97363717, 0.97665626, 0.98002007, 0.98343948, 0.98548557,\n",
              "         0.98964168, 0.99011985, 0.98986687, 0.98997807, 0.98988355,\n",
              "         0.98973898, 0.98967226, 0.98953882, 0.98934422, 0.98953048]),\n",
              "  'split3_train_score': array([0.9945772 , 0.99614804, 0.99769074, 0.99880306, 0.99934741,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              "  'split4_test_score': array([0.98107917, 0.98403912, 0.9864895 , 0.9885751 , 0.98972511,\n",
              "         0.99371812, 0.99414136, 0.99389354, 0.99349536, 0.99336727,\n",
              "         0.99237876, 0.99209753, 0.99216992, 0.99183856, 0.9916158 ]),\n",
              "  'split4_train_score': array([0.99427477, 0.99593337, 0.99743619, 0.99874866, 0.99933882,\n",
              "         0.99999548, 0.99999861, 1.        , 1.        , 1.        ,\n",
              "         1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              "  'std_fit_time': array([0.0058678 , 0.29934599, 0.00770195, 0.00409295, 0.02017516,\n",
              "         0.01213609, 0.00927474, 0.0122758 , 0.01989517, 0.02055084,\n",
              "         0.01329442, 0.00936171, 0.0452048 , 0.01752624, 0.51945848]),\n",
              "  'std_score_time': array([0.00072668, 0.00700603, 0.00047122, 0.00046071, 0.00244143,\n",
              "         0.00050282, 0.00184463, 0.00043078, 0.00072381, 0.00114743,\n",
              "         0.00072074, 0.00056753, 0.00059179, 0.00088418, 0.00557539]),\n",
              "  'std_test_score': array([0.00285378, 0.0026791 , 0.00236963, 0.00182534, 0.00151279,\n",
              "         0.00150415, 0.00145765, 0.00148229, 0.0013864 , 0.00139131,\n",
              "         0.00133326, 0.00134962, 0.0014365 , 0.00142236, 0.0012991 ]),\n",
              "  'std_train_score': array([3.09607635e-04, 1.98224239e-04, 1.65215343e-04, 5.69275286e-05,\n",
              "         1.27786744e-05, 1.58181542e-06, 4.65989847e-07, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00])},\n",
              " {'learning_rate': 0.1, 'n_estimators': 1200},\n",
              " 0.9925075043107296)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "HO30o8pbdK2W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 绘图查看auc与准确率的变化情况"
      ]
    },
    {
      "metadata": {
        "id": "ujuBUN7sdK2d",
        "colab_type": "code",
        "outputId": "ce6ca814-f1c2-44ce-ae7f-2ff19aa8c271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize = (15, 5))\n",
        "p1 = fig.add_subplot(1,2,1)\n",
        "p1.plot(auc_Score)\n",
        "p1.set_ylabel(\"AUC Score\")\n",
        "p1.set_title(\"AUC Score\")\n",
        "\n",
        "p2 = fig.add_subplot(1,2,2)\n",
        "p2.plot(accuracy)\n",
        "p2.set_ylabel(\"Accuracy\")\n",
        "p2.set_title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAE+CAYAAAAzqRVFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhCYQAAAAAKIITSAAAAAARJH/D+r+g17D082mAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5e3321b3d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}